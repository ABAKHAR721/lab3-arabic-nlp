{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXK0Dc17V2Nv"
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers transformers beautifulsoup4 nltk datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiAtkkvaV3zB"
   },
   "outputs": [],
   "source": [
    "import requests, re, time, pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import torch, torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from transformers import AutoTokenizer, GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download only what's needed (avoid broken punkt_tab)\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Arabic stopwords\n",
    "arabic_stopwords = set(stopwords.words(\"arabic\"))\n",
    "\n",
    "# Semantic sentence model\n",
    "sbert_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "reference = \"Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ ÙŠØªØ­Ø¯Ø« Ø¹Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„ÙˆØ·Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ\"\n",
    "ref_embedding = sbert_model.encode(reference, convert_to_tensor=True)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745074698287,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "hrKEtnVPWWZM"
   },
   "outputs": [],
   "source": [
    "def get_article_links(base_url, pages=2):\n",
    "    links = []\n",
    "    for page in range(1, pages + 1):\n",
    "        url = f\"{base_url}?page={page}\"\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            if \"/news/\" in a[\"href\"] and not a[\"href\"].startswith(\"https\"):\n",
    "                links.append(\"https://www.aljazeera.net\" + a[\"href\"])\n",
    "    return list(set(links))\n",
    "\n",
    "def extract_text(url):\n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "        return \" \".join(p.get_text() for p in soup.find_all(\"p\")).strip()\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745074699969,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "bFNWQVPMWZsU"
   },
   "outputs": [],
   "source": [
    "def semantic_score(text):\n",
    "    emb = sbert_model.encode(text, convert_to_tensor=True)\n",
    "    sim = util.cos_sim(emb, ref_embedding).item()\n",
    "    return round(max(0.0, min(sim * 10, 10.0)), 2)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^\\u0600-\\u06FF\\s]\", \"\", text)  # Keep Arabic\n",
    "    tokens = text.split()  # Simple whitespace tokenizer\n",
    "    tokens = [t for t in tokens if t not in arabic_stopwords and len(t) > 2]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1745074701561,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "wPVPo-coWbjL"
   },
   "outputs": [],
   "source": [
    "def scrape_articles():\n",
    "    links = get_article_links(\"https://www.aljazeera.net/news/\")\n",
    "    data = []\n",
    "    for link in links[:20]:\n",
    "        text = extract_text(link)\n",
    "        if len(text.split()) > 50:\n",
    "            score = semantic_score(text)\n",
    "            data.append({\"Text\": text, \"Score\": score})\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"tokens\"] = df[\"Text\"].apply(preprocess)\n",
    "    df.to_csv(\"arabic_dataset.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1EoFp2aXBsD"
   },
   "outputs": [],
   "source": [
    "data = scrape_articles()\n",
    "data[\"tokens\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "34a643d9599443a9a71ef1c5cba35a25",
      "a2d7579030bb472088fe2abe6c1b7adc",
      "2cf1fdb222374f3eb31bb43e9d133bc4",
      "df64cf92570b4cdab5acb5b67335fe90",
      "57ce242c802d4d4bb02d2218dc5a42dc",
      "7db8573e019f453b8dea6e3d2f1f95b8",
      "ef182785555043bd940a4f63a06e4da5",
      "a7d9b9128cf14f6f807b8aa18a0f005a",
      "dc32c9e64cc841c9bf18e26069af0e5c",
      "917c22ff98d64b09bb171682aee92a67",
      "859b9d23ede945aabd104ab5cd4d937d",
      "8e6c2aa3d0f84e18b0ceaae20330f0cc",
      "465ae5300c534be5a967d917ce2c3de0",
      "2471be2c6d5841ff89d15fb83497170b",
      "37ebdaadbafd408e8b9f494832a06d80",
      "86551df4195c4b2db4e7355155e8f78b",
      "f99a409c174642b4a6b4ded0e7e8f4fe",
      "ee737402de624eab96f2e433992b79cf",
      "13f72e40573f43208789306b8b15a757",
      "d577e988dd6f478c8d4e7acbfd284332",
      "3f255ce853604d6d8dedd8aff5daefa4",
      "41d9757ce1274992894ec1f01b23a182",
      "17ac19ad0a824f0aa3f4b04f1d6834d1",
      "f5aea849e3d6442a92bf2fa20c0f1f6e",
      "03cb1f36e2464b7b87b55d30cdab7d40",
      "156338ed8d5a42a9940d94928095386c",
      "646f57de9645486486ff0d6f27764d39",
      "7616df2f524c4e319df3bd6651eecdd5",
      "051a2fbe162d4bb5800a3883df1979f5",
      "25d2d77877ba4c0caf46b556b69fce61",
      "bfc0aff1df6440259a7927684b5c9472",
      "9bead89b5f9649a485b4f1f56013c867",
      "a9eeaec6daba4da9812540faa6bf76d5",
      "2a3c7a3e977249bcbc7e15f499e767f2",
      "99098e27d4de4302acc352ee3626c224",
      "65b914492ada49278228f848b3b91b7b",
      "359cb9b50880423195e3bd603e11c9c5",
      "eed838cc18d342cb8e0b0e8818b0e2f3",
      "7c4dc4cb64c34e2f8112cd1cd311bc39",
      "b9388beb7991462e93f335d08ef19454",
      "212a5f19cf234a48ad39ec88623b84ab",
      "76d3e89094fb46878616a5a0200b4e86",
      "8d8e324479214882bb2ee5a4d7ec9c13",
      "f38af3c496f4445c850698011c962d46"
     ]
    },
    "executionInfo": {
     "elapsed": 1825,
     "status": "ok",
     "timestamp": 1745074717522,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "2MuceEkHWc7A",
    "outputId": "0956d1bd-5345-4049-9c44-f90797b21470"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a643d9599443a9a71ef1c5cba35a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6c2aa3d0f84e18b0ceaae20330f0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ac19ad0a824f0aa3f4b04f1d6834d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/334k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3c7a3e977249bcbc7e15f499e767f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
    "data[\"input_ids\"] = data[\"tokens\"].apply(lambda x: tokenizer.encode(\" \".join(x), padding=\"max_length\", max_length=100, truncation=True))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"input_ids\"].tolist(), data[\"Score\"].tolist(), test_size=0.2)\n",
    "\n",
    "class ArabicDataset(Dataset):\n",
    "    def __init__(self, encodings, scores):\n",
    "        self.encodings = encodings\n",
    "        self.scores = scores\n",
    "    def __len__(self): return len(self.encodings)\n",
    "    def __getitem__(self, idx): return torch.tensor(self.encodings[idx]), torch.tensor(self.scores[idx], dtype=torch.float)\n",
    "\n",
    "train_loader = DataLoader(ArabicDataset(X_train, y_train), batch_size=2)\n",
    "test_loader = DataLoader(ArabicDataset(X_test, y_test), batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745074719791,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "90WCMdgBWg35"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, rnn_type, vocab_size, embed_dim=128, hidden_dim=64, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        rnn_cls = {\"rnn\": nn.RNN, \"gru\": nn.GRU, \"lstm\": nn.LSTM}[rnn_type]\n",
    "        self.rnn = rnn_cls(embed_dim, hidden_dim, batch_first=True, bidirectional=bidirectional)\n",
    "        self.bidirectional = bidirectional\n",
    "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, h = self.rnn(x)\n",
    "\n",
    "        # Handle LSTM hidden state tuple (h, c)\n",
    "        if isinstance(h, tuple):\n",
    "            h = h[0]\n",
    "\n",
    "        # Bidirectional: concatenate forward and backward hidden states\n",
    "        if self.bidirectional:\n",
    "            h_out = torch.cat((h[0], h[1]), dim=1)  # shape [batch, hidden*2]\n",
    "        else:\n",
    "            h_out = h[-1]  # shape [batch, hidden]\n",
    "\n",
    "        return self.fc(h_out).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745074724904,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "Tgb0GFZoWh_D"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(rnn_type, bidirectional=False):\n",
    "    print(f\"\\n==> Training {rnn_type.upper()} {'Bi' if bidirectional else ''}RNN\")\n",
    "    model = RNNModel(rnn_type, tokenizer.vocab_size, bidirectional=bidirectional).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(3):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            preds = model(X_batch)\n",
    "            loss = loss_fn(preds.view(-1), y_batch.view(-1))  # Fix shape mismatch\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    preds, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            preds.extend(y_pred.cpu().view(-1).numpy())\n",
    "            actuals.extend(y_batch.numpy())\n",
    "\n",
    "    print(\"MSE:\", round(mean_squared_error(actuals, preds), 4))\n",
    "    print(\"RÂ²:\", round(r2_score(actuals, preds), 4))\n",
    "\n",
    "    # BLEU evaluation with rounding\n",
    "    bleu_scores = [\n",
    "        sentence_bleu([[str(round(act, 1))]], str(round(pred, 1)),\n",
    "                      smoothing_function=SmoothingFunction().method4)\n",
    "        for pred, act in zip(preds, actuals)\n",
    "    ]\n",
    "    print(\"BLEU Score:\", round(sum(bleu_scores) / len(bleu_scores), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1745074729869,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "5V6KuQroXzzw",
    "outputId": "93c82642-b2f2-4939-b0be-a5a4b012d158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Training RNN RNN\n",
      "MSE: 0.6279\n",
      "RÂ²: -1.6907\n",
      "BLEU Score: 0.0\n",
      "\n",
      "==> Training GRU RNN\n",
      "MSE: 1.5393\n",
      "RÂ²: -5.5962\n",
      "BLEU Score: 0.0\n",
      "\n",
      "==> Training LSTM RNN\n",
      "MSE: 5.7165\n",
      "RÂ²: -23.4969\n",
      "BLEU Score: 0.0\n",
      "\n",
      "==> Training LSTM BiRNN\n",
      "MSE: 2.0246\n",
      "RÂ²: -7.6761\n",
      "BLEU Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\"rnn\")\n",
    "train_and_evaluate(\"gru\")\n",
    "train_and_evaluate(\"lstm\")\n",
    "train_and_evaluate(\"lstm\", bidirectional=True)  # BiLSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318,
     "referenced_widgets": [
      "a0ab256ca5ac4ae392e0f700fabf0ee0",
      "2cc74649b5e942e9a4184f92d9067198",
      "f517a9ed590c4c439b3cc92678db8023",
      "d181edcb4d9c4de984cb4e9139173e20",
      "af4d464b940b469389d330976e62724c",
      "1161db94f3354246987996e22fe4f1f8",
      "8d1dc9ababfa4e7598be771aeb4c0862",
      "cd3b146f04384e4fb0219019312a9d99",
      "3d293ba544ec49ea802a9a5fbae60708",
      "0fe61a013b254b20a93655f8ce788b3f",
      "4a012c3d7d5e41069e1ea88b7ce5a972",
      "62e9ade4218c4e49a75a0de6414d7b37",
      "92f613cf93864bef9732c6171b44048b",
      "8949d72955cc4085b18afb718768c113",
      "b5c573c93d4c4e4788ff6c307e22b4d1",
      "16307c884781403a85817b9ef3a1855f",
      "b426d9b2302d4604b296eb472e3a1556",
      "beaeb25effed4d299622c2d5a472f1e8",
      "6f8fe90abc54421b802b4ed62512d60b",
      "f8bc72ffebff4c78b9bde9b27e25cab0",
      "e8b7f13fdc574143a190d749f840801c",
      "5ba407d2bc98416fae745eb88899dabf",
      "87dfd69866e24629b931cc83509baa24",
      "b81f9cb4558140528d9e2175cc379633",
      "60888e3b35254ee8a3e69413814cb105",
      "00d28396dce446bfa371ce6d27974929",
      "f6edc51701c543bb95a1716c10815b35",
      "2d73285c00ef4ff9b5ce0f2375696934",
      "8296b4d3544c427690280ca7e480e72e",
      "7917f78623474a779231c950557b5e5b",
      "3fa72929115e4868a1c89ace12875b69",
      "dcc473ecd3b5457e997dee66c950fc80",
      "550cc29d2bc548a581d57be3cf401e60",
      "17ee4ed913d846febca758973832aa1e",
      "77d8b36cf1ed48eca4dabc915e6d0d47",
      "3b88d5e4bd5d436ab0acb27bed6df2f1",
      "73bfad19ccdf4182832acd2ffa85b06d",
      "4cef52dfdeaa4640badd1c0ebc35916c",
      "18c9c1915aca4e878ec39413a7b07cfc",
      "8eb2b71e3034494bb4a52ad642fefbe9",
      "f8916bbfe9f3451583f8457f01a52982",
      "5503a517decf40adaf178d1ceb81fdcb",
      "301398ba4f034cd48cd38c2e9da9a0e2",
      "518d3e72933b401aa6d7931002217b4b",
      "eeea1db5ebf84d24952bd50499ab1daf",
      "90a76a2550b946a39755d2f26292c9ae",
      "c768bafe575840a3be848fbe57233879",
      "30b479facdbe4d808c83b8041fab847c",
      "71bab85f85a84c93bffdad984e22dd8d",
      "f5b2e931d3eb48ad9fd6acafc00be810",
      "5d4c5c827abc4aa98e4c80623462f591",
      "5c923de765fb4cf4baaab4e790742705",
      "614d6e8f2f584523b8e10dbbbd808eed",
      "d2e5058b797a46018f0f2950459e431c",
      "87687f05ac4b4d558315da8ab7841304"
     ]
    },
    "executionInfo": {
     "elapsed": 6445,
     "status": "ok",
     "timestamp": 1745074741731,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "oaM9BkuMWjom",
    "outputId": "4f1edb82-3ed1-48b4-ba93-e6f1c0f149ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Arabic Text Generation with GPT-2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ab256ca5ac4ae392e0f700fabf0ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e9ade4218c4e49a75a0de6414d7b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.50M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dfd69866e24629b931cc83509baa24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/4.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ee4ed913d846febca758973832aa1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeea1db5ebf84d24952bd50499ab1daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Paragraph:\n",
      "\n",
      "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø³ÙŠØ³Ø§Ù‡Ù… ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„Ø£Ø±Ø¯Ù† \" .ÙˆØ£Ø¶Ø§Ù Ø£Ù† \" Ù‡Ù†Ø§Ùƒ ØªØ­Ø¯ÙŠØ§Øª Ø£Ø®Ø±Ù‰ ØªÙˆØ§Ø¬Ù‡ Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„Ø£Ø±Ø¯Ù† ØŒ Ù…Ù†Ù‡Ø§ Ù†Ù‚Øµ Ø§Ù„ÙƒÙˆØ§Ø¯Ø± Ø§Ù„Ø¨Ø´Ø±ÙŠØ© Ø§Ù„Ù…Ø¤Ù‡Ù„Ø© ØŒ ÙˆØ¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø· ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØªØ¹Ù„ÙŠÙ… ØŒ ÙˆØ¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø© ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØªØ¹Ù„ÙŠÙ… \" .ÙˆØ£ÙˆØ¶Ø­ Ø£Ù† \" ÙˆØ¬ÙˆØ¯ ØªØ¹Ù„ÙŠÙ… Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ø·Ù„Ø¨Ø© ØŒ Ø³ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ Ø²ÙŠØ§Ø¯Ø© Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„ØªØ³Ø±Ø¨ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ ØŒ ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ ØªÙ‚Ù„ÙŠÙ„ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ³Ø±Ø¨ Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠ ØŒ ÙˆÙƒØ°Ù„Ùƒ Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø¨Ø© ØŒ ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ Ø²ÙŠØ§Ø¯Ø© Ù†Ø³Ø¨Ø© Ø§Ù„Ø§Ù„ØªØ­Ø§Ù‚ Ø¨Ø§Ù„Ù…Ø¯Ø§Ø±Ø³\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Arabic Text Generation with GPT-2 ---\")\n",
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"aubmindlab/aragpt2-base\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"aubmindlab/aragpt2-base\").to(device)\n",
    "gpt2_model.eval()\n",
    "\n",
    "prompt = \"Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø³ÙŠØ³Ø§Ù‡Ù… ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ…\"\n",
    "inputs = gpt2_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated = gpt2_model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=80,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    temperature=0.7,\n",
    "    pad_token_id=gpt2_tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Paragraph:\\n\")\n",
    "print(gpt2_tokenizer.decode(generated[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1163,
     "status": "ok",
     "timestamp": 1745074747310,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "TFZNciDSYKYF",
    "outputId": "236df970-5a3f-4d93-cf5f-1c4c7749aaf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø³ÙŠØ³Ø§Ù‡Ù… ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø¹Ù† Ø¨Ø¹Ø¯ ØŒ ÙˆØ³ÙŠØªÙ…ÙƒÙ† Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙˆØ±Ø§Øª ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ø¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ØŒ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ù†ÙØ³Ù‡ Ø³ÙŠØ³Ø§Ù‡Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ .ÙˆÙƒØ§Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù‚Ø¯ Ø¨Ø¯Ø£ ÙÙŠ ØªØ·ÙˆÙŠØ± Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø®ØµØµ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø¹Ù† Ø¨Ø¹Ø¯ ØŒ ÙˆÙ‚Ø¯ Ø¨Ø¯Ø£ Ø¨ØªØ·ÙˆÙŠØ±Ù‡ ÙÙŠ Ø¹Ø§Ù… 2013 .\n",
      "\n",
      "Sample 2:\n",
      "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø³ÙŠØ³Ø§Ù‡Ù… ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¹Ø§Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ø±Ø¯Ù† Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¹Ø§Ù„ÙŠ Ø¨ÙˆØ¬Ù‡ Ø®Ø§Øµ .\n",
      "\n",
      "Sample 3:\n",
      "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø³ÙŠØ³Ø§Ù‡Ù… ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ±ÙØ¹ ÙƒÙØ§Ø¡ØªÙ‡ ØŒ Ø®ØµÙˆØµØ§ ÙÙŠ Ø¸Ù„ Ù…Ø§ ØªØ´Ù‡Ø¯Ù‡ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨Ù„Ø¯Ø§Ù† Ù…Ù† Ø§Ù†ØªØ´Ø§Ø± Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø© ØŒ Ø§Ù„Ø£Ù…Ø± Ø§Ù„Ø°ÙŠ ÙŠØ³ØªØ¯Ø¹ÙŠ ÙˆØ¶Ø¹ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ÙˆØ·Ù†ÙŠØ© ÙˆØ·Ù†ÙŠØ© Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ… ØŒ Ø®Ø§ØµØ© Ø£Ù†Ù‡ Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø°ÙŠ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠÙØªÙ‚Ø± Ø¥Ù„Ù‰ Ø§Ù„ÙƒÙØ§Ø¡Ø§Øª ÙˆØ§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø´Ø£Ù† .ÙˆØ£ÙƒØ¯ Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± ÙŠØªØ·Ù„Ø¨ Ù…Ù† Ø§Ù„Ø¬Ø§Ù…Ø¹Ø§Øª Ø§Ù„Ø®Ø§ØµØ© ØŒ ØªÙƒÙˆÙŠÙ† ÙˆØªØ¯Ø±ÙŠØ¨ ÙˆØªØ£Ù‡ÙŠÙ„ ÙƒÙˆØ§Ø¯Ø±Ù‡Ø§ Ø§Ù„ÙˆØ·Ù†ÙŠØ© ØŒ Ù…Ù† Ø®Ù„Ø§Ù„ ØªØ·ÙˆÙŠØ± Ø¨Ø±Ø§Ù…Ø¬Ù‡Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø´Ø£Ù† ØŒ ÙˆÙƒØ°Ù„Ùƒ Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ© Ø§Ù„Ù…ØªØ®ØµØµØ© Ù„Øª\n"
     ]
    }
   ],
   "source": [
    "generated = gpt2_model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=80,\n",
    "    num_return_sequences=3,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    temperature=0.9,\n",
    "    pad_token_id=gpt2_tokenizer.eos_token_id\n",
    ")\n",
    "for i, sample in enumerate(generated):\n",
    "    print(f\"\\nSample {i+1}:\\n{gpt2_tokenizer.decode(sample, skip_special_tokens=True)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "each-HCUj7KK"
   },
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1745074773447,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "qQVJpWxAj9c-"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"arabic_dataset.csv\")\n",
    "with open(\"gpt2_arabic_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in df[\"Text\"]:\n",
    "        f.write(line.strip() + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1745074788754,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "oGoiWSwvj-Uz",
    "outputId": "a3b02109-bf4d-4bdd-8a72-7247420c9429"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "model_name = \"aubmindlab/aragpt2-base\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT2 has no pad token\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"gpt2_arabic_train.txt\",\n",
    "    block_size=128\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Language modeling, not masked\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1745074800651,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "kzDgS3MxkDY8"
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 99045,
     "status": "ok",
     "timestamp": 1745074908362,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "HggiHbkwkF9r",
    "outputId": "dd65c2c9-ced4-4564-ebb7-5d183e403f12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlegendsit1234\u001b[0m (\u001b[33mlegendsit1234-university-abdelmalek-essaadi\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250419_150122-63h4lf9q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/legendsit1234-university-abdelmalek-essaadi/huggingface/runs/63h4lf9q' target=\"_blank\">./gpt2_arabic_finetuned</a></strong> to <a href='https://wandb.ai/legendsit1234-university-abdelmalek-essaadi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/legendsit1234-university-abdelmalek-essaadi/huggingface' target=\"_blank\">https://wandb.ai/legendsit1234-university-abdelmalek-essaadi/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/legendsit1234-university-abdelmalek-essaadi/huggingface/runs/63h4lf9q' target=\"_blank\">https://wandb.ai/legendsit1234-university-abdelmalek-essaadi/huggingface/runs/63h4lf9q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75, training_loss=6.208026529947917, metrics={'train_runtime': 97.6374, 'train_samples_per_second': 1.506, 'train_steps_per_second': 0.768, 'total_flos': 9602482176000.0, 'train_loss': 6.208026529947917, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_arabic_finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=500,\n",
    "    save_total_limit=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8261,
     "status": "ok",
     "timestamp": 1745074929151,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "KH6Y8v2TkaZp",
    "outputId": "278e4de5-4ac4-4386-d459-9ad8bef3a954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2_arabic_finetuned/tokenizer_config.json',\n",
       " './gpt2_arabic_finetuned/special_tokens_map.json',\n",
       " './gpt2_arabic_finetuned/vocab.json',\n",
       " './gpt2_arabic_finetuned/merges.txt',\n",
       " './gpt2_arabic_finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./gpt2_arabic_finetuned\")\n",
    "tokenizer.save_pretrained(\"./gpt2_arabic_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3552,
     "status": "ok",
     "timestamp": 1745074935330,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "a1k56vDJkhSz",
    "outputId": "3cd5236e-4ec9-4b2c-f5ab-8434e2897a09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø¯ÙŠØ« ØŒ ÙˆÙÙŠ Ø¸Ù„ Ù…Ø§ ÙŠØ´Ù‡Ø¯Ù‡ Ø§Ù„Ø¹Ø§Ù„Ù… Ù…Ù† ØªØºÙŠØ±Ø§Øª Ø¹Ù…ÙŠÙ‚Ø© Ø¹Ù„Ù‰ Ù…Ø®ØªÙ„Ù Ø§Ù„ØµØ¹Ø¯ Ø§Ù„Ø³ÙŠØ§Ø³ÙŠØ© ÙˆØ§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© ÙˆØ§Ù„Ø«Ù‚Ø§ÙÙŠØ©ØŒ ÙØ¶Ù„Ø§ Ø¹Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª Ø§Ù„ØªÙŠ ØªÙˆØ§Ø¬Ù‡ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ø¨Ø£Ø³Ø±Ù‡ØŒ Ø®Ø§ØµØ© ÙÙŠÙ…Ø§ ÙŠØªØ¹Ù„Ù‚ Ø¨Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù„Ø§Ø¬Ø¦ÙŠÙ† Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠÙŠÙ†ØŒ Ø§Ù„Ø°ÙŠÙ† ÙŠØ¹ÙŠØ´ÙˆÙ† ÙÙŠ Ø§Ù„Ø£Ø±Ø§Ø¶ÙŠ Ø§Ù„Ù…Ø­ØªÙ„Ø© Ù…Ù†Ø° Ø¹Ø§Ù… 1948ØŒ Ø¥Ø° Ù„Ø§ ØªØ²Ø§Ù„ Ø£Ø¹Ø¯Ø§Ø¯Ù‡Ù… ØªØªØ²Ø§ÙŠØ¯ØŒ Ø¥Ù„Ø§ Ø£Ù† Ù‡Ù†Ø§Ùƒ ØªØ­Ø¯ÙŠØ§Øª ÙƒØ¨ÙŠØ±Ø© ØªÙˆØ§Ø¬Ù‡Ù‡Ù…ØŒ ØªØªÙ…Ø«Ù„ ÙÙŠ Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„Ø§Ø­ØªÙ„Ø§Ù„ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ ÙÙŠ Ø§Ù†ØªÙ‡Ø§Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ÙŠØŒ ÙˆØ§Ù†ØªÙ‡Ø§Ùƒ Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ØŒ Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ø§Ù†ØªÙ‡Ø§ÙƒØ§Øª Ø§Ù„Ø¬Ø³ÙŠÙ…Ø© Ù„Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø¥Ù†Ø³Ø§Ù† Ø§Ù„Ø£Ø®Ø±Ù‰ØŒ Ø¨Ù…Ø§ ÙÙŠÙ‡Ø§ Ø¬Ø±Ø§Ø¦Ù… Ø§Ù„Ø­Ø±Ø¨ ÙˆØ§Ù„Ø¬Ø±Ø§Ø¦Ù… Ø¶Ø¯\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"./gpt2_arabic_finetuned\", tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø¯ÙŠØ«\"\n",
    "outputs = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2840,
     "status": "ok",
     "timestamp": 1745075076223,
     "user": {
      "displayName": "Abdssamad Abkhar",
      "userId": "15335981712636211350"
     },
     "user_tz": -60
    },
    "id": "rh6nhyUJlGyK",
    "outputId": "1aca219e-b53a-438d-d8bb-41c006c9e9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø¯ÙŠØ«ØŒ ÙˆØ°Ù„Ùƒ Ù…Ù† Ø£Ø¬Ù„ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø¹Ø§Ù„ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø© ØŒ ÙˆØ£Ù† ÙŠÙƒÙˆÙ† Ù„Ù‡Ø§ Ø¯ÙˆØ± ÙØ¹Ø§Ù„ ÙÙŠ ØªØ­Ù‚ÙŠÙ‚ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø¯ÙˆØ± Ø§Ù„Ø°ÙŠ ØªÙ‚ÙˆÙ… Ø¨Ù‡ ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ù…Ù…Ø«Ù„Ø© ÙÙŠ Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ø¨Ù…Ø­Ø§ÙØ¸Ø© Ø¬Ù†ÙˆØ¨ Ø³ÙŠÙ†Ø§Ø¡ØŒ Ø­ÙŠØ« ØªØ¹Ù…Ù„ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù…Ø¹ Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ø¨Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ù‡Ø¬ ØªØ¹Ù„ÙŠÙ…ÙŠØ© ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØ£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ§Ø­ØªÙŠØ§Ø¬Ø§ØªÙ‡Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©ØŒ ÙƒÙ…Ø§ ØªØ³Ø¹Ù‰ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¥Ù„Ù‰ ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¨Ù…Ø§ ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø±Ø§Ù‡Ù†Ø© ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©ØŒ ÙˆØªØ¹Ù…Ù„ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¹Ù„Ù‰ ØªÙˆÙÙŠØ± ÙƒØ§ÙØ© Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª ÙˆØ§Ù„ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆÙÙ‚Ø§ Ù„Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙŠ ÙˆØ¶Ø¹ØªÙ‡Ø§ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„Ø«Ù‚Ø§ÙØ© ÙˆØ§Ù„Ø¹Ù„ÙˆÙ… \" Ø§Ù„ÙŠÙˆÙ†Ø³ÙƒÙˆ \"ï¿½\n",
      "\n",
      "Sample 2:\n",
      "Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø¯ÙŠØ«ØŒ ÙˆØ°Ù„Ùƒ Ù…Ù† Ø£Ø¬Ù„ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø¹Ø§Ù„ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø© ØŒ ÙˆØ£Ù† ÙŠÙƒÙˆÙ† Ù„Ù‡Ø§ Ø¯ÙˆØ± ÙØ¹Ø§Ù„ ÙÙŠ ØªØ­Ù‚ÙŠÙ‚ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø¯ÙˆØ± Ø§Ù„Ø°ÙŠ ØªÙ‚ÙˆÙ… Ø¨Ù‡ ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ù…Ù…Ø«Ù„Ø© ÙÙŠ Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ø¨Ù…Ø­Ø§ÙØ¸Ø© Ø¬Ù†ÙˆØ¨ Ø³ÙŠÙ†Ø§Ø¡ØŒ Ø­ÙŠØ« ØªØ¹Ù…Ù„ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù…Ø¹ Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ø¨Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ù‡Ø¬ ØªØ¹Ù„ÙŠÙ…ÙŠØ© ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØ£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ§Ø­ØªÙŠØ§Ø¬Ø§ØªÙ‡Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©ØŒ ÙƒÙ…Ø§ ØªØ³Ø¹Ù‰ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¥Ù„Ù‰ ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¨Ù…Ø§ ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø±Ø§Ù‡Ù†Ø© ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©ØŒ ÙˆØªØ¹Ù…Ù„ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¹Ù„Ù‰ ØªÙˆÙÙŠØ± ÙƒØ§ÙØ© Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª ÙˆØ§Ù„ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆÙÙ‚Ø§ Ù„Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙŠ ÙˆØ¶Ø¹ØªÙ‡Ø§ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„Ø«Ù‚Ø§ÙØ© ÙˆØ§Ù„Ø¹Ù„ÙˆÙ… \" Ø§Ù„ÙŠÙˆÙ†ÙŠØ³ÙƒÙˆ \"\n",
      "\n",
      "Sample 3:\n",
      "Ø£Ù‡Ù…ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø¯ÙŠØ«ØŒ ÙˆØ°Ù„Ùƒ Ù…Ù† Ø£Ø¬Ù„ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø¹Ø§Ù„ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø© ØŒ ÙˆØ£Ù† ÙŠÙƒÙˆÙ† Ù„Ù‡Ø§ Ø¯ÙˆØ± ÙØ¹Ø§Ù„ ÙÙŠ ØªØ­Ù‚ÙŠÙ‚ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø¯ÙˆØ± Ø§Ù„Ø°ÙŠ ØªÙ‚ÙˆÙ… Ø¨Ù‡ ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ù…Ù…Ø«Ù„Ø© ÙÙŠ Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ø¨Ù…Ø­Ø§ÙØ¸Ø© Ø¬Ù†ÙˆØ¨ Ø³ÙŠÙ†Ø§Ø¡ØŒ Ø­ÙŠØ« ØªØ¹Ù…Ù„ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù…Ø¹ Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… Ø¨Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© Ø¹Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ù‡Ø¬ ØªØ¹Ù„ÙŠÙ…ÙŠØ© ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØ£ÙˆÙ„ÙŠØ§Ø¡ Ø§Ù„Ø£Ù…ÙˆØ± ÙˆØ§Ø­ØªÙŠØ§Ø¬Ø§ØªÙ‡Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©ØŒ ÙƒÙ…Ø§ ØªØ³Ø¹Ù‰ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¥Ù„Ù‰ ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¨Ù…Ø§ ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø±Ø§Ù‡Ù†Ø© ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©ØŒ ÙˆØªØ¹Ù…Ù„ Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ø¹Ù„Ù‰ ØªÙˆÙÙŠØ± ÙƒØ§ÙØ© Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª ÙˆØ§Ù„ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„Ù„Ø§Ø²Ù…Ø© Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆÙÙ‚Ø§ Ù„Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ø§Ù„ØªÙŠ ÙˆØ¶Ø¹ØªÙ‡Ø§ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ù„Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„Ø«Ù‚Ø§ÙØ© \" Ø§Ù„ÙŠÙˆÙ†Ø³ÙƒÙˆ \"ï¿½\n"
     ]
    }
   ],
   "source": [
    "outputs = generator(prompt, max_length=120, num_return_sequences=3, temperature=0.9, top_p=0.95)\n",
    "for i, out in enumerate(outputs):\n",
    "    print(f\"\\nSample {i+1}:\\n{out['generated_text']}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNe4Ffj0d2Oce0ZHvlsrRJa",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
